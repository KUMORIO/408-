## 主题一：多项选择

### 实验环境：

#### 基本信息：

平台：colab

模型：hfl/chinese-macbert-base

数据集：c^3数据集

#### 详细信息：

##### 模型介绍：

**模型简介：**`hfl/chinese-macbert-base` 是由哈工大的自然语言处理团队（HFL）开发的一款中文预训练语言模型。它基于 RoBERTa 架构，结合了 BERT 和 RoBERTa 的优点，并针对中文进行了优化，以提高在中文自然语言处理任务中的表现。

**预训练任务与数据来源：**该模型使用了多种预训练任务，如 Masked Language Model（MLM）和 Masked Token Prediction（MTP），在大量中文文本数据上进行训练，包括新闻、维基百科和社交媒体等，以便更好地理解和处理中文语境中的复杂语言现象。

**应用任务广泛**：`Chinese-MacBERT-Base` 版本具有较小的模型规模，适合在需要平衡性能和计算资源的场景中使用，广泛应用于文本分类、问答系统、命名实体识别等多种中文自然语言处理任务。

##### 数据集介绍：

**数据集内容：**c^3数据集是首个中文多项选择，机器阅读理解数据集。收集的主要是形式自由的多项选择题，来自汉语水平考试和民族汉语考试的阅读材料，包括试卷和练习。

**数据集数量：**C3数据集包含13369篇文章和19577个问题，其中的60%用是训练集，20%是验证集，20%是测试集。

### 实验过程：

#### 数据集预处理

将一个包含上下文、问题、选项和答案的数据集预处理成适合模型训练的格式

1. **初始化数据容器**：创建用于存储处理后数据的空列表，包括 `context`（上下文文本）、`question_choice`（问题和选项的组合）和 `labels`（选项的标签）。
2. **遍历数据**：遍历数据集中每个样本，将上下文文本通过换行符连接成一个完整字符串，将问题和选项提取出来。
3. **处理选项**：
   - 对每个选项，将相同的上下文和问题选项组合添加到 `context` 和 `question_choice` 列表中。
   - 如果选项数量不足 4 个，为每个缺失的选项添加一个 “不知道” 作为占位符，以确保每个样本都有 4 个选项。
4. **保存标签**：记录每个样本的正确答案选项的索引，并将其添加到 `labels` 列表中。
5. **标记化**：使用分词器将 `context` 和 `question_choice` 列表中的文本进行标记化处理，设置最大长度为 256 个 token，并确保文本长度不超过最大值。
6. **重组标记化结果**：将标记化后的数据重新组织成每个样本包含 4 个选项的格式。
7. **添加标签**：将每个样本的标签添加到标记化数据中，形成最终的预处理结果。

#### 创建评估函数

计算模型在给定数据集上的预测准确率，以评估模型的性能。

定义了一个函数用于计算准确率。这个函数的输入是模型的预测结果和真实标签，它将模型的预测概率转换为具体的预测类别，然后利用准确率评估工具来比较预测结果与真实标签之间的一致性。最终，这个函数会返回模型在数据集上的预测准确率，帮助评估模型的整体性能。

#### 配置训练参数

配置训练模型时的各种训练参数

1. **输出目录**：指定训练过程中生成的模型检查点和日志文件的保存位置，以便后续使用和分析。
2. **训练和评估批量大小**：设置在训练和评估阶段每个设备（如 GPU）上处理的样本数量。这里设置为每个设备 16 个样本。
3. **训练轮次**：定义模型训练的总轮次数，这里设置为 10 轮，以确保模型在数据集上进行充分训练。
4. **日志打印频率**：指定训练过程中每隔多少步打印一次训练日志，以便监控训练进度和状态，这里设置为每 50 步打印一次。
5. **评估策略**：设置模型评估的策略，这里配置为每轮训练结束后进行评估，以检查模型的性能变化。
6. **保存策略**：指定模型保存的策略，这里配置为每轮训练结束后保存一次模型检查点，以便可以恢复到最佳状态。
7. **训练结束时加载最佳模型**：确保在训练完成后，自动加载在验证集上表现最好的模型，以获得最佳的训练结果。
8. **半精度训练**：启用半精度浮点数训练（FP16），以减少内存占用并加快训练速度，适用于支持 FP16 的硬件。

#### 创建训练器

创建一个训练器对象，用于管理模型的训练和评估过程。

1. **模型**：指定要训练的模型对象，这个模型将会在训练过程中被更新和优化。
2. **训练参数**：将之前定义的训练参数传递给训练器，以配置训练的细节，例如批量大小、训练轮次等。
3. **分词器**：提供用于文本处理的分词器，以便将输入数据转换为模型可以理解的格式。
4. **训练数据集**：指定用于训练的已标记数据集，以便训练器可以使用这些数据来训练模型。
5. **评估数据集**：指定用于模型评估的已标记数据集，这些数据集将在训练过程中用于验证模型的性能。
6. **计算指标函数**：提供一个用于计算模型评估指标的函数，以便在训练和评估过程中跟踪模型的性能。

#### 模型预测

为多项选择题模型提供预测服务

1. **初始化**：类的构造函数接受一个模型和一个分词器，并将它们保存为实例变量。它还确定模型当前所在的设备（例如 CPU 或 GPU），以便后续处理数据时可以正确地将数据移动到该设备上。
2. **数据预处理**：`preprocess` 方法负责将输入的上下文、问题和选项转换为模型可以接受的格式。它将每个选项与上下文和问题组合起来，并使用分词器进行处理，包括截断和填充，最终将数据转换为张量格式。
3. **模型预测**：`predict` 方法将预处理后的输入数据传递给模型，获取模型的预测结果。它首先将数据移动到适当的设备上，然后执行模型的前向传播，返回模型的输出（即 logits）。
4. **结果后处理**：`postprocess` 方法将模型的输出转换为具体的预测结果。它通过获取 logits 中最大值的索引来确定模型的预测类别，并将该类别映射回原始的选项列表，返回最终的选择结果。
5. **调用**：`__call__` 方法使得该类的实例可以像函数一样被调用。它依次调用预处理、预测和后处理方法，最终返回模型对给定上下文、问题和选项的预测结果。

## 主题二：文本相似度检测

### 实验环境：

#### 基本信息：

平台：colab

模型：hfl/chinese-macbert-base

数据集：AFQMC数据集

#### 详细信息：

##### 模型介绍：

**模型简介：**`hfl/chinese-macbert-base` 是由哈工大的自然语言处理团队（HFL）开发的一款中文预训练语言模型。它基于 RoBERTa 架构，结合了 BERT 和 RoBERTa 的优点，并针对中文进行了优化，以提高在中文自然语言处理任务中的表现。

**预训练任务与数据来源：**该模型使用了多种预训练任务，如 Masked Language Model（MLM）和 Masked Token Prediction（MTP），在大量中文文本数据上进行训练，包括新闻、维基百科和社交媒体等，以便更好地理解和处理中文语境中的复杂语言现象。

**应用任务广泛**：`Chinese-MacBERT-Base` 版本具有较小的模型规模，适合在需要平衡性能和计算资源的场景中使用，广泛应用于文本分类、问答系统、命名实体识别等多种中文自然语言处理任务。

##### 数据集介绍：

**数据集内容：**AFQMC（Ant Financial Question Matching Corpus）数据集是由蚂蚁金服（Ant Financial）发布的一个用于语义相似度计算的数据集。它主要用于评估算法在判断两个问题（或句子）之间的语义相似度方面的性能。在AFQMC数据集中，任务是判断两个句子是否表达了相同的意图或语义。具体来说，对于每对句子，模型需要预测它们是否具有相同的语义含义。这个任务类似于问答系统中的问题匹配或客服对话中的语义理解。

**数据集数量：**AFQMC数据集包含34,334对句子作为训练集、4,316对句子作为验证集以及3,861对句子作为测试集。其中，训练集占总数据的约 77.1%，验证集占约 9.4%，测试集占约 8.8%。

### 实验过程：

#### 数据集预处理

对一个文本数据集进行预处理，以便使用 `hfl/chinese-macbert-base` 模型进行训练。

1. **导入库和加载分词器**：
   代码首先导入了 PyTorch 和 Hugging Face 的 `AutoTokenizer`，然后加载了 `hfl/chinese-macbert-base` 模型对应的分词器。这些分词器用于将原始文本转换为模型可以理解的格式。

2. **定义处理函数**：
   `process_function` 是一个数据处理函数。它的作用是从输入的样本中提取句子对和标签，并将这些文本数据转换为模型需要的格式：
   - 从每个样本中提取两个句子（`sentence1` 和 `sentence2`）及其对应的标签（`label`）。
   - 将两个句子添加到一个列表中，同时将标签转换为 1 或 -1，并存储在另一个列表中。
   - 使用分词器对句子进行分词处理，将其转换为模型所需的 `input_ids`、`attention_mask` 和 `token_type_ids`。处理时将文本长度统一到 128，并进行填充或截断。
   - 将分词结果按照每两个句子一组进行整理，以符合模型的输入要求。
   - 将标签添加到处理后的数据中，并返回这些数据。

3. **应用处理函数并移除原列**：
   使用 `dataset.map` 方法将 `process_function` 应用到整个数据集上。`batched=True` 表示批量处理数据，提高效率。通过 `remove_columns` 参数删除原始数据集中不需要的列，只保留处理后的结果。

4. **输出处理后的数据集**：
   最后，代码显示处理后的数据集，包含了分词后的文本数据和标签。

将原始文本数据进行预处理，转换为适合 `hfl/chinese-macbert-base` 模型训练的格式。

#### 创建模型 

用于处理包含两个句子的任务，并计算它们的相似度。

1. **导入库和定义模型类**：
   - 从 `transformers` 库中导入了 `BertForSequenceClassification`、`BertPreTrainedModel` 和 `BertModel`。
   - 从 `typing` 中导入了 `Optional` 类型提示。
   - 从 `torch.nn` 导入了 `CosineSimilarity` 和 `CosineEmbeddingLoss`。

2. **定义 `DualModel` 类**：
   - 继承自 `BertPreTrainedModel`，用于在 BERT 基础上实现自定义功能。
   - 在 `__init__` 方法中，初始化了一个 BERT 模型 `self.bert`，并调用了 `post_init()` 方法完成模型的初始化。

3. **定义 `forward` 方法**：
   - **输入参数**：
     - `input_ids`、`attention_mask`、`token_type_ids` 等用于模型的输入，`labels` 用于计算损失。
   - **处理步骤**：
     - **Step 1**：将输入的 `input_ids`、`attention_mask` 和 `token_type_ids` 划分为两个句子（`senA` 和 `senB`）的输入。
     - **Step 2**：分别通过 BERT 模型获取句子 `senA` 和 `senB` 的向量表示。使用 `self.bert` 对这两个句子进行编码，获取其池化输出（即 `[batch, hidden]`）。
     - **Step 3**：计算句子 `senA` 和 `senB` 向量表示的余弦相似度，得到一个 `[batch, ]` 的相似度分数。
     - **Step 4**：如果提供了 `labels`，使用 `CosineEmbeddingLoss` 计算损失。该损失函数用于训练模型，使得相似的句子对的相似度值接近设定的目标（这里为 0.3），而不相似的句子对的相似度值远离目标值。

4. **模型实例化**：
   - 使用 `DualModel.from_pretrained` 方法从指定路径加载预训练的 `DualModel` 模型，这里路径为 `/content/drive/MyDrive/多项选择/hfl-chinese-macbert-base`。

用于处理句子对相似度计算的 BERT 模型，并通过余弦相似度来评估两个句子的相似程度，同时可以计算相应的损失用于模型训练。

#### 创建评估函数

用于计算模型的评估指标，包括准确率（accuracy）和 F1 分数。具体功能如下：

1. **输入参数**：
   - `eval_predict` 是一个包含两个元素的元组：`predictions`（模型的预测结果）和 `labels`（真实标签）。

2. **处理预测结果和标签**：
   - `predictions = [int(p > 0.7) for p in predictions]`：将模型的预测结果转换为二值标签（0 或 1）。如果预测值大于 0.7，则标记为 1，否则标记为 0。
   - `labels = [int(l > 0) for l in labels]`：将真实标签转换为二值标签。如果真实标签大于 0，则标记为 1，否则标记为 0。

3. **计算评估指标**：
   - `acc = acc_metric.compute(predictions=predictions, references=labels)`：使用自定义的准确率指标计算预测结果的准确率。
   - `f1 = f1_metirc.compute(predictions=predictions, references=labels)`：使用自定义的 F1 指标计算预测结果的 F1 分数。

4. **更新并返回结果**：
   - `acc.update(f1)`：将计算得到的 F1 分数更新到准确率结果中。这通常意味着将 F1 分数添加到准确率指标的输出中。
   - `return acc`：返回包含准确率和 F1 分数的结果。

#### 创建TrainingArguments

用于配置模型训练过程的各项参数，确保训练过程按照预设的要求进行。

1. **输出目录**：指定了训练过程中生成的模型文件和日志的保存位置，以便后续访问和管理。

2. **批量大小**：设定了训练和验证时每个设备（如 GPU）处理样本的数量，这决定了模型每次更新时使用的样本数。

3. **日志打印频率**：设定了训练过程中日志信息的打印频率，帮助监控训练进展和模型表现。

4. **评估和保存策略**：定义了在训练期间进行模型评估和保存的策略，例如每个训练周期结束时进行评估和保存，以跟踪模型的性能和保存最佳模型。

5. **最大保存模型数量**：限制了保存的模型检查点的数量，避免存储空间被过多的模型文件占用。

6. **学习率和权重衰减**：配置了训练过程中模型参数更新的步长（学习率）和正则化力度（权重衰减），帮助模型更好地收敛并防止过拟合。

7. **最佳模型指标**：指定了用于选择最佳模型的评估指标，训练过程将基于该指标（如 F1 分数）来确定和保存性能最好的模型。

8. **加载最优模型**：训练结束后自动加载表现最好的模型，以确保最终得到的模型具有最佳性能。

9. **训练轮数**：设定了模型训练的总轮数，每轮包括对整个训练数据集的完整遍历。

配置了模型训练的关键参数，以确保训练过程高效、有效，并能够得到最佳的模型结果。

#### 创建Trainer

创建一个 `Trainer` 对象，负责模型的训练和评估。

1. **模型**：
   - 将需要训练的模型指定给 `Trainer` 对象。

2. **训练参数**：
   - 配置训练过程中的各种参数，包括学习率、批量大小、训练和验证的频率、保存策略等，确保训练过程按照预设的条件进行。

3. **分词器**：
   - 提供一个分词器，用于将文本数据转换成模型可以处理的格式，从而保证模型能够正确接收输入数据。

4. **数据集**：
   - 指定训练数据集和验证数据集，以便模型可以在这些数据上进行训练和评估。

5. **评估指标**：
   - 提供一个评估函数，用于计算模型的性能指标，如准确率和 F1 分数，以便监控模型的表现并进行调整。

通过以上配置，`Trainer` 对象将管理整个训练过程，包括数据的处理、模型的训练、性能的评估以及模型的保存。

#### 模型预测

用于处理和评估句子相似度。

1. **初始化**：
   - `__init__` 方法接受一个模型和一个分词器作为输入，并将模型的 BERT 部分和设备（如 GPU）存储为实例变量。模型的 BERT 部分用于提取句子的特征，设备用于确保计算在正确的硬件上进行。

2. **数据预处理**：
   - `preprocess` 方法接受两个句子 `senA` 和 `senB`，使用分词器将这两个句子转换为模型可以接受的格式，包括生成适合的输入张量。此方法还会对输入文本进行截断和填充，以确保输入张量的长度一致。

3. **模型预测**：
   - `predict` 方法将处理后的输入数据转移到计算设备上（如 GPU），然后通过模型进行预测，获取句子的特征表示。这里的 `logits` 是模型输出的特征向量，通常包含每个句子的上下文嵌入。

4. **后处理**：
   - `postprocess` 方法计算两个句子向量之间的余弦相似度。通过余弦相似度，量化两个句子之间的相似度，结果是一个浮动值，表示两个句子的相似程度。

5. **调用**：
   - `__call__` 方法使得这个类的实例可以像函数一样被调用。它接受两个句子 `senA` 和 `senB`，然后执行预处理、预测和后处理步骤。可以通过 `return_vector` 参数选择是否返回句子的特征向量和相似度值。如果 `return_vector` 为 `True`，则返回特征向量和相似度值；否则，仅返回相似度值。

封装了句子相似度计算的完整流程，从文本预处理、模型推理到相似度计算，使得计算两个句子相似度变得简洁而高效。