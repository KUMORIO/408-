## 余弦相似度和欧氏距离是两种常用的计算向量相似度的方法。

1. **余弦相似度**:
   - 公式:$( \text{cosine similarity} = \frac{\mathbf{A} \cdot \mathbf{B}}{\|\mathbf{A}\| \|\mathbf{B}\|} $)
   - 解释: 这里，$\mathbf{A} $ 和$  \mathbf{B}  $是两个非零向量，而$  \mathbf{A} \cdot \mathbf{B}$ 是它们的点积，$ \|\mathbf{A}\| 和 \|\mathbf{B}\|  $是它们的模。余弦相似度测量的是两个向量在方向上的相似度，范围从 -1（完全相反）到 1（完全相同）。它常用于文本分析中，比如在文档相似度或者用户偏好分析中。

2. **欧氏距离**:
   - 公式: $$ \text{Euclidean distance} = \sqrt{\sum_{i=1}^{n}(A_i - B_i)^2}$ $
   - 解释: 在这个公式中，$ A_i  $和 $B_i $ 是向量$  \mathbf{A} $和$\mathbf{B} $中的对应元素。欧氏距离是在多维空间中计算两点之间“直线”距离的方法。它是几何学中的常见概念，通常用于各种分类和聚类算法中。

这两种方法虽然都用于衡量相似度，但关注的角度不同。余弦相似度关注方向的相似度而不考虑幅度，而欧氏距离计算的是空间中的实际距离。在实际应用中，选择哪一种方法取决于具体问题的性质和需求。



## 协同过滤是一种推荐系统算法，用于预测用户对物品的喜好程度。

它主要有两种类型：基于用户的协同过滤（User-based Collaborative Filtering）和基于物品的协同过滤（Item-based Collaborative Filtering）。虽然具体的算法和实现可能会有所不同，以下是两种常见方法中用户对物品喜好程度预测的基本公式：

### 1. 基于用户的协同过滤（User-based Collaborative Filtering）

在这种方法中，系统会寻找和目标用户兴趣相似的其他用户，然后基于这些相似用户的评分来预测目标用户对某个物品的喜好程度。假设我们想要预测用户 $ u $ 对物品 $ i $ 的喜好程度：

$$
\text{Preference}(u, i) = \overline{r}_u + \frac{\sum\limits_{v \in N(u)} \text{sim}(u, v) \cdot (r_{v,i} - \overline{r}_v)}{\sum\limits_{v \in N(u)} |\text{sim}(u, v)|}
$$

- $$\overline{r}_u $$ 是用户 $ u $ 的平均评分。
- $$ r_{v,i}  $$是用户 $ v $ 对物品 $ i $ 的评分。
- \$$\overline{r}_v $ $$是用户  v  的平均评分。
- $ \text{sim}(u, v) $ 是用户 $ u $ 和 $ v $ 之间的相似度。
- $ N(u) $ 是与用户 $ u $ 最相似的用户集合。

### 2. 基于物品的协同过滤（Item-based Collaborative Filtering）

与基于用户的方法相反，基于物品的协同过滤关注于找到与目标物品相似的其他物品，并基于用户对这些相似物品的评分来预测其对目标物品的喜好程度。假设我们想要预测用户 $ u $ 对物品 $ i $ 的喜好程度：
$$
\text{Preference}(u, i) = \frac{\sum\limits_{j \in N(i)} \text{sim}(i, j) \cdot r_{u,j}}{\sum\limits_{j \in N(i)} |\text{sim}(i, j)|}
$$

- $ r_{u,j} $ 是用户 $ u $ 对物品 $ j $ 的评分。
- $ \text{sim}(i, j) $ 是物品 $ i $ 和 $ j $ 之间的相似度。
- $ N(i) $ 是与物品 $ i $ 最相似的物品集合。

在实际应用中，相似度（similarity）的计算可以通过多种方法实现，如余弦相似度、皮尔逊相关系数、Jaccard相似度等。此外，为了提高推荐的准确性和效率，可能还会引入正则化项、维度约简技术（如矩阵分解）以及其他机器学习方法。



基于用户的协同过滤（User-based Collaborative Filtering, UCF）和基于物品的协同过滤（Item-based Collaborative Filtering, ICF）是推荐系统中的两种主流技术。它们都试图通过分析用户与物品之间的交互数据（如评分或购买历史）来预测用户对物品的喜好。尽管它们的目标相似，但在实现方式上有显著的差异。

## 基于用户的协同过滤和基于物品的协同过滤的区别和联系

### 基于用户的协同过滤 (UCF):

1. **原理**: UCF通过寻找和目标用户兴趣相似的其他用户来进行推荐。如果一个用户A与用户B在过去对一些物品有相似的评分或偏好，那么用户A可能会对用户B评分过而他自己尚未评分的物品感兴趣。

2. **优点**:
   - 直观易懂，模拟人类推荐行为。
   - 能够提供意外的、多样化的推荐。

3. **缺点**:
   - **可扩展性**: 随着用户数量的增加，计算量急剧增加。
   - **稀疏性问题**: 在用户-物品交互矩阵中，可能存在大量的空白项。
   - **冷启动问题**: 对于新用户，由于缺乏历史数据，难以找到相似用户。

### 基于物品的协同过滤 (ICF):

1. **原理**: ICF通过计算物品之间的相似度来进行推荐。如果一个用户对某个物品评分高，系统会推荐与这个物品相似的其他物品。

2. **优点**:
   - **性能**: 通常比UCF更易于扩展和维护，因为物品的数量通常远少于用户数量。
   - **稳定性**: 物品的属性比用户的兴趣更稳定，因此物品间相似度不需要频繁更新。

3. **缺点**:
   - 可能会过度专注于用户已显示出兴趣的物品类型，导致推荐的多样性降低。
   - 对于新物品，同样面临冷启动问题。

### 区别和联系:

- **计算焦点**: UCF关注于找到相似的用户，而ICF关注于找到相似的物品。
- **性能和可扩展性**: 通常情况下，ICF在大型数据集上比UCF更易于扩展，因为物品的数量通常少于用户数量。
- **推荐多样性**: UCF倾向于提供更多样化的推荐，而ICF可能导致较窄范围的推荐。
- **冷启动问题**: 两者都面临冷启动问题，但表现形式不同。UCF难以为新用户提供准确推荐，而ICF难以处理新物品。

尽管UCF和ICF在理论和实现上存在差异，但它们可以组合使用以利用各自的优势。在实际的推荐系统中，通常会结合多种策略，包括UCF、ICF以及其他基于内容的方法和机器学习技术，以提高推荐的准确性和用户满意度。

## 那么经过softmax函数作用后概率分别就是 [0.0903,0.2447,0.665],如果这个样本正确的分类是第二个的话，那么计算出来的偏导是什么



当使用 Softmax 函数进行多类分类时，常配合交叉熵损失函数（Cross-Entropy Loss）来进行训练。假设一个样本的正确分类是第二个类别，我们可以计算关于 Softmax 输出的交叉熵损失的偏导数。这在神经网络的反向传播中非常重要。

假设 Softmax 输出为 $$[0.0903, 0.2447, 0.665]$$，并且正确的分类是第二个，即目标输出（或标签）是 $$[0, 1, 0]$$。交叉熵损失函数定义为：

$$
L = -\sum_{i} y_i \log(p_i)
$$
其中 $$y_i$$ 是目标值（在这个例子中是 $$[0, 1, 0]$$），$$p_i$$ 是 `Softmax `输出（在这个例子中是 $$[0.0903, 0.2447, 0.665]$$）。

为了计算偏导数，我们只关注非零项，因为 $$y_i$$ 中的零项在求和中不产生贡献。因此，损失函数简化为：

$$
L = -\log(p_2)
$$

其中 $$p_2 = 0.2447$$ 是第二个类别的概率。然后我们计算损失 $$L$$ 关于 `Softmax `函数输入 $$z_i$$ 的偏导数。在 Softmax 的情况下，偏导数有一个很好的性质：

$$
\frac{\partial L}{\partial z_i} = p_i - y_i
$$
因此，对于每个类别 $$i$$，偏导数是 `Softmax` 输出 $$p_i$$ 减去目标值 $$y_i$$。在我们的例子中，偏导数将是：

- 对于第一个类别：$$\frac{\partial L}{\partial z_1} = 0.0903 - 0$$
- 对于第二个类别（正确的类别）：$$\frac{\partial L}{\partial z_2} = 0.2447 - 1$$
- 对于第三个类别：$$\frac{\partial L}{\partial z_3} = 0.665 - 0$$

这些偏导数表明我们需要如何调整各个类别的分数（通过调整权重和偏差），以减少损失，从而更接近正确的分类。在实践中，这些偏导数将用于梯度下降或其他优化算法来更新模型的参数。



## `softmax`偏导公式

![image-20231224000353928](C:/Users/Lenovo/AppData/Roaming/Typora/typora-user-images/image-20231224000353928.png)

1. **Softmax 函数**:
   $$
   p_i = \frac{e^{z_i}}{\sum_{k=1}^{K} e^{z_k}}
   $$

2. **交叉熵损失函数**:
   $$
   L = -\sum_{j=1}^{K} y_j \log(p_j)
   $$

3. **求偏导数的链式法则**:
   $$
   \frac{\partial L}{\partial z_i} = \sum_{j=1}^{K} \frac{\partial L}{\partial p_j} \frac{\partial p_j}{\partial z_i}
   $$

4. **计算 $$\frac{\partial L}{\partial p_j}$$**:
   $$
   \frac{\partial L}{\partial p_j} = -\frac{y_j}{p_j}
   $$

5. **计算 $$\frac{\partial p_j}{\partial z_i}$$**:
   
   - 当 $$i = j$$ 时:
     $$
     \frac{\partial p_j}{\partial z_i} = p_i(1 - p_i)
     $$
   - 当 $$i \neq j$$ 时:
     $$
     \frac{\partial p_j}{\partial z_i} = -p_i p_j
     $$
   
6. **结合上述公式得到最终的偏导数**:
   $$
   \frac{\partial L}{\partial z_i} = p_i - y_i
   $$

这些公式展示了从` Softmax` 函数和交叉熵损失函数出发，如何通过链式法则求得损失函数 $$L$$ 相对于 `Softmax `输入 $$z_i$$ 的偏导数。

## `softmax`梯度下降的公式

在神经网络的`softmax`层中，对权重 $$w $$ 和偏置 $$b $$ 的更新是基于损失函数 $$L $$ 的梯度。softmax层通常用于多类分类问题的输出层，它将输入向量转换为概率分布。在这个层中，损失函数（通常是交叉熵损失）相对于权重和偏置的梯度可以这样计算：

1. **softmax函数**：首先，假设您有一个线性输出 $$z = w^Tx + b $$，其中 $$x $$ 是输入，$$w $$ 是权重，$$b $$ 是偏置。softmax函数 $$\sigma(z)_i $$ 对于第 $$i $$ 个类别的输出是：

   $$\sigma(z)_i = \frac{e^{z_i}}{\sum_{j} e^{z_j}} $$

   这里，$$z_i $$ 是向量 $$z $$ 中第 $$i $$ 个元素，分母是对所有输出类别的 $$e^{z_j} $$ 的求和。

2. **交叉熵损失函数**：对于多类分类，交叉熵损失函数 $$L $$ 可以这样定义：

   $$L = -\sum_{i} y_i \log(\sigma(z)_i) $$

   其中，$$y_i $$ 是目标类别的真实概率分布，通常表示为one-hot编码。

3. **对权重的梯度**：损失函数 $$L $$ 关于权重 $$w $$ 的梯度 $$\frac{\partial L}{\partial w} $$ 可以通过链式法则计算：

   $$\frac{\partial L}{\partial w} = \frac{\partial L}{\partial \sigma(z)} \cdot \frac{\partial \sigma(z)}{\partial z} \cdot \frac{\partial z}{\partial w} $$

4. **对偏置的梯度**：类似地，损失函数 $$L $$ 关于偏置 $$b $$ 的梯度 $$\frac{\partial L}{\partial b} $$ 是：

   $$\frac{\partial L}{\partial b} = \frac{\partial L}{\partial \sigma(z)} \cdot \frac{\partial \sigma(z)}{\partial z} \cdot \frac{\partial z}{\partial b} $$

在这两种情况下，您需要计算这些偏导数，然后使用梯度下降来更新权重和偏置：

- 对于权重：$$w_{\text{new}} = w_{\text{old}} - \alpha \times \frac{\partial L}{\partial w} $$
- 对于偏置：$$b_{\text{new}} = b_{\text{old}} - \alpha \times \frac{\partial L}{\partial b} $$

其中，$$\alpha $$ 是学习率，一个预先设定的小数值，用于控制学习的步长。这个过程在每次迭代中重复，以逐步减少损失函数的值，从而训练出一个更好的模型。



## torch.scatter_()

[pytorch scatter_ 用法 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/187401278)



## random.sample()

[py001- random中sample()函数的用法_random.sample-CSDN博客](https://blog.csdn.net/qq_37281522/article/details/85032470)

## sorted()

`ascending` 参数是在进行排序操作时用于指定排序顺序的参数，它通常用于控制升序（ascending order）或降序（descending order）的排序方式。以下是对 `ascending` 参数的说明：

- 当 `ascending` 参数设置为 `True` 时，排序将按照升序进行，也就是从小到大排序。这是默认的排序方式。

- 当 `ascending` 参数设置为 `False` 时，排序将按照降序进行，也就是从大到小排序。

举个例子，假设有一个列表 `my_list` 包含一些数字：

```python
my_list = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]
```

如果你想按照升序排列这个列表，你可以这样做：

```python
sorted_list_ascending = sorted(my_list, ascending=True)
print(sorted_list_ascending)
```

输出将会是：

```
[1, 1, 2, 3, 3, 4, 5, 5, 5, 6, 9]
```

如果你想按照降序排列这个列表，你可以这样做：

```python
sorted_list_descending = sorted(my_list, ascending=False)
print(sorted_list_descending)
```

输出将会是：

```
[9, 6, 5, 5, 5, 4, 3, 3, 2, 1, 1]
```

通过设置 `ascending` 参数，你可以灵活地控制排序的顺序，以满足你的需求。

`sorted` 函数可以用于对序列进行排序，包括列表、元组、字典的键等。要实现降序排序，你可以使用 `sorted` 函数的 `reverse` 参数或使用 `key` 参数结合 `lambda` 函数。下面分别介绍这两种方法：

**方法 1：使用 `reverse` 参数**

```python
my_list = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]

# 使用 reverse 参数将列表降序排列
sorted_list = sorted(my_list, reverse=True)

print(sorted_list)
```

**方法 2：使用 `key` 参数和 `lambda` 函数**

```python
my_list = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]

# 使用 key 参数和 lambda 函数将列表降序排列
sorted_list = sorted(my_list, key=lambda x: -x)

print(sorted_list)
```

这两种方法都会将列表 `my_list` 按照降序排列。你可以根据需要选择其中一种方法。方法 2 使用了 `key` 参数和 `lambda` 函数，可以更灵活地定义排序规则，适用于更复杂的情况。